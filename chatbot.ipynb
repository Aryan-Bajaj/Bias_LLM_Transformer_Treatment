import re

import numpy as np

import tensorflow as tf

from tensorflow.keras.preprocessing.text import Tokenizer

from tensorflow.keras.preprocessing.sequence import pad_sequences

from tensorflow.keras.layers import Embedding, LSTM, Dense

from tensorflow.keras.models import Sequential

import pandas as pd

from IPython.display import Image, display

from langdetect import detect

from googletrans import Translator

from datetime import datetime, timedelta

from transformers import pipeline

import emoji

 

class KWSMLHelpBot:

    def __init__(self, csv_filepath):

        self.data_df = pd.read_csv(csv_filepath)

        self.locations = self.data_df['Location'].unique().tolist()

        self.intents = self.data_df['Intent'].unique().tolist()

        self.goodbye_words = ["bye", "goodbye", "exit", "quit", "Farewell", "Adieu", "See you later", "Sayonara", "Ciao", "Toodle-oo", "Cheerio", "So long", "Hasta luego", "Later", "Goodnight", "Godspeed", "Bon voyage", "Take care", "Till we meet again", "Ta-ta", "Catch you later", "Peace out", "Until next time", "Adios","Tsch√ºss", "Auf Wiedersehen", "Beenden", "Farewell", "Adieu", "Bis sp√§ter", "Sayonara", "Ciao", "Toodle-oo", "Cheerio", "So long", "Hasta luego", "Sp√§ter", "Gute Nacht", "Gute Reise", "Auf Wiedersehen", "Bis bald", "Pass auf dich auf", "Bis wir uns wiedersehen", "Tsch√ºss", "Bis sp√§ter", "Bis bald", "Bis zum n√§chsten Mal"]

        self.tokenizer = Tokenizer()

        self.tokenizer.fit_on_texts(self.intents)

        self.max_length = max([len(seq) for seq in self.tokenizer.texts_to_sequences(self.intents)])

        self.model = self.build_model()

        self.train_model(self.create_training_data())

        self.translator = Translator()

        self.language_dict = {'en': 'English', 'de': 'German'}

        self.emotion_dict = {'Neutral': 'üòê', 'Happy': 'üòÉ', 'Sad': 'üò¢', 'Angry': 'üò†', 'Scared': 'üò®'}  

        self.interactions_df = pd.DataFrame(columns=['Timestamp', 'User Input', 'Language Detected', 'Bot Response', 'Emotion Detected'])

 

    def build_model(self):

        input_dim = len(self.tokenizer.word_index) + 1

        model = Sequential([

            Embedding(input_dim=input_dim, output_dim=64, input_length=self.max_length),

            LSTM(100),

            Dense(len(self.intents), activation='softmax')

        ])

        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

        return model

 

    def train_model(self, train_data):

        user_inputs, intent_indices = zip(*train_data)

        sequences = self.tokenizer.texts_to_sequences(user_inputs)

        padded_sequences = pad_sequences(sequences, maxlen=self.max_length)

        intent_indices = tf.convert_to_tensor(intent_indices)

       

        print("Training started...")

        for epoch in range(5):

            print(f"Epoch {epoch + 1}/5")

            self.model.fit(padded_sequences, intent_indices, epochs=1)

            print("\n")

        print("Training completed.")

 

    def create_training_data(self):

        train_data = [(intent, i) for i, intent in enumerate(self.intents)]

        return train_data

 

    def classify_intent(self, user_input):

        sequence = self.tokenizer.texts_to_sequences([user_input])

        padded_sequence = pad_sequences(sequence, maxlen=self.max_length)

        intent_index = np.argmax(self.model.predict(padded_sequence), axis=-1)[0]

        return intent_index

 

    def print_response(self, response, language='en'):

        response_german = self.translator.translate(response, dest='de').text if language == 'de' else response

        print(f"Bot: {response_german}")

 

    def store_interaction(self, user_input, bot_response, language_detected, emotion_detected):

        timestamp = (datetime.now() + timedelta(hours=1)).strftime("%Y-%m-%d %H:%M:%S")  # Adjusted timestamp

        emoticon = self.emotion_dict.get(emotion_detected, 'üòê')  # Default to neutral emoticon

        new_row = {'Timestamp': timestamp, 'User Input': user_input, 'Bot Response': bot_response, 'Language Detected': language_detected, 'Emotion Detected': f'{emotion_detected} {emoticon}'}

        self.interactions_df = pd.concat([self.interactions_df, pd.DataFrame([new_row])], ignore_index=True)

 

    def answer_question(self, user_input):

        user_language = detect(user_input)

 

        if user_language not in self.language_dict:

            user_language = 'en'  # Set English as default language

 

        print(f"Detected language: {self.language_dict[user_language]}")

 

        user_input_lower = user_input.lower()

 

        if any(word.lower() in user_input_lower for word in self.goodbye_words):

            goodbye_response = "Auf Wiedersehen! Wenn Sie weitere Fragen haben, k√∂nnen Sie diese gerne stellen." if user_language == 'de' else "Goodbye! If you have more questions, feel free to ask."

            self.print_response(goodbye_response, language=user_language)

            self.store_interaction(user_input, goodbye_response, user_language, 'Neutral')

            return False

 

        location_match = re.search(r'\b(?:' + '|'.join(map(re.escape, [loc.lower() for loc in self.locations])) + r')\b', user_input_lower, re.IGNORECASE)

 

        if location_match:

            found_location = location_match.group(0).capitalize()

        else:

            translated_prompt = self.translator.translate(f"F√ºr welche Standort fragen Sie? Verf√ºgbare Standorte sind: {', '.join(self.locations)}\nUser: ", dest=user_language).text

            found_location = input(translated_prompt).capitalize()

 

            while found_location.lower() not in [loc.lower() for loc in self.locations]:

                location_not_trained_response = f"Ich bin noch nicht f√ºr {found_location} geschult. Verf√ºgbare Standorte sind: {', '.join(self.locations)}" if user_language == 'de' else f"Sorry, I am not trained for {found_location}. Available locations are: {', '.join(self.locations)}"

                self.print_response(location_not_trained_response, language=user_language)

                found_location = input(translated_prompt).capitalize()

 

        user_intent = self.classify_intent(user_input_lower)

        found_intent = self.intents[user_intent]

 

        answer_data = self.data_df[(self.data_df['Location'] == found_location) & (self.data_df['Intent'] == found_intent)]

 

        if not answer_data.empty:

            for _, row in answer_data.iterrows():

                if pd.notna(row['Details']):

                    response_details = f"Bot: {row['Details']}" if user_language == 'de' else row['Details']

                    self.print_response(response_details, language=user_language)

                    self.store_interaction(user_input, response_details, user_language, 'Neutral')

 

        self.handle_images(found_intent, user_input_lower)

 

        detected_emotion = self.detect_emotion(user_input_lower)

        self.store_interaction(user_input, '', user_language, detected_emotion)

 

        return True

 

    def detect_emotion(self, user_input):

        emotion_classifier = pipeline('sentiment-analysis')

        result = emotion_classifier(user_input)[0]

        label = result['label'].lower()

 

        if label == 'positive':

            return 'Happy'

        elif label == 'negative':

            return 'Sad' if 'not' not in user_input else 'Angry'

        else:

            return 'Scared' if any(char in emoji.UNICODE_EMOJI.values() for char in user_input) else 'Neutral'

 

    def handle_images(self, found_intent, user_input_lower):

        PRODUCTION_ORDER_STATUS_PHRASES = ["Produktionsauftr√§gen", "production order status", "production status", "order status", "Produktionsauftragsstatus", "Produktionsstatus", "Auftragsstatus"]

        if found_intent == "production_order_status" and any(phrase in user_input_lower for phrase in PRODUCTION_ORDER_STATUS_PHRASES):

            image_path = "/content/Check production order status.png"

            #self.print_response("Bitte finden Sie den angeh√§ngten Screenshot.", 'de')

            #self.store_interaction(user_input_lower, "Bitte finden Sie den angeh√§ngten Screenshot.", 'de', 'Neutral')

            display(Image(filename=image_path, format='png'))

 

        CONFIRMATION_CHECK_PHRASES = ["Best√§tigung", "Best√§tigungspr√ºfung ","confirmation check", "check confirmation", "Best√§tigungspr√ºfung", "Best√§tigung √ºberpr√ºfen"]

        if found_intent == "confirmation_check" and any(phrase in user_input_lower for phrase in CONFIRMATION_CHECK_PHRASES):

            image_path_1 = "/content/Confirmation Check 1.png"

            image_path_2 = "/content/Confirmation Check 2.png"

            image_path_3 = "/content/Confirmation Check 3.png"

            image_path_4 = "/content/Confirmation Check 4.png"

            self.print_response("Bitte finden Sie die angeh√§ngten Screenshots.", 'de')

            self.store_interaction(user_input_lower, "Bitte finden Sie die angeh√§ngten Screenshots.", 'de', 'Neutral')

            display(Image(filename=image_path_1, format='png'))

            display(Image(filename=image_path_2, format='png'))

            display(Image(filename=image_path_3, format='png'))

            display(Image(filename=image_path_4, format='png'))

 

# Example usage

csv_file = '/content/kwsm_help_bot_data.csv'

bot = KWSMLHelpBot(csv_file)

 

print('''\nHello! I am KWS ML Help BOT. How can I help you today?

\nHallo! Ich bin KWS ML Help BOT. Wie kann ich Ihnen heute helfen?

 

''')

 

while True:

    user_input = input("User: ")

    continue_chat = bot.answer_question(user_input)

 

    if not continue_chat:

        break
